{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport time\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#首先读取train文件，并保存为df_train数据框，进行描述性统计\ndf_train = pd.read_csv(\"../input/train.csv\")\ndf_train.describe()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\ncount  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \nmean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel6   pixel7   pixel8    ...         pixel774      pixel775  \\\ncount  42000.0  42000.0  42000.0    ...     42000.000000  42000.000000   \nmean       0.0      0.0      0.0    ...         0.219286      0.117095   \nstd        0.0      0.0      0.0    ...         6.312890      4.633819   \nmin        0.0      0.0      0.0    ...         0.000000      0.000000   \n25%        0.0      0.0      0.0    ...         0.000000      0.000000   \n50%        0.0      0.0      0.0    ...         0.000000      0.000000   \n75%        0.0      0.0      0.0    ...         0.000000      0.000000   \nmax        0.0      0.0      0.0    ...       254.000000    254.000000   \n\n           pixel776     pixel777      pixel778      pixel779  pixel780  \\\ncount  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \nmean       0.059024      0.02019      0.017238      0.002857       0.0   \nstd        3.274488      1.75987      1.894498      0.414264       0.0   \nmin        0.000000      0.00000      0.000000      0.000000       0.0   \n25%        0.000000      0.00000      0.000000      0.000000       0.0   \n50%        0.000000      0.00000      0.000000      0.000000       0.0   \n75%        0.000000      0.00000      0.000000      0.000000       0.0   \nmax      253.000000    253.00000    254.000000     62.000000       0.0   \n\n       pixel781  pixel782  pixel783  \ncount   42000.0   42000.0   42000.0  \nmean        0.0       0.0       0.0  \nstd         0.0       0.0       0.0  \nmin         0.0       0.0       0.0  \n25%         0.0       0.0       0.0  \n50%         0.0       0.0       0.0  \n75%         0.0       0.0       0.0  \nmax         0.0       0.0       0.0  \n\n[8 rows x 785 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "fe48342b-c503-40e5-a562-70b5aa11c887",
        "_uuid": "983eaf1f5e43a1e16c0d2649674964fd374de95d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#然后读取train文件，并保存为df_test数据框，并进行描述性统计\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf_test.describe()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\ncount  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0   \nmean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel8   pixel9    ...         pixel774      pixel775      pixel776  \\\ncount  28000.0  28000.0    ...     28000.000000  28000.000000  28000.000000   \nmean       0.0      0.0    ...         0.164607      0.073214      0.028036   \nstd        0.0      0.0    ...         5.473293      3.616811      1.813602   \nmin        0.0      0.0    ...         0.000000      0.000000      0.000000   \n25%        0.0      0.0    ...         0.000000      0.000000      0.000000   \n50%        0.0      0.0    ...         0.000000      0.000000      0.000000   \n75%        0.0      0.0    ...         0.000000      0.000000      0.000000   \nmax        0.0      0.0    ...       253.000000    254.000000    193.000000   \n\n           pixel777      pixel778  pixel779  pixel780  pixel781  pixel782  \\\ncount  28000.000000  28000.000000   28000.0   28000.0   28000.0   28000.0   \nmean       0.011250      0.006536       0.0       0.0       0.0       0.0   \nstd        1.205211      0.807475       0.0       0.0       0.0       0.0   \nmin        0.000000      0.000000       0.0       0.0       0.0       0.0   \n25%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n50%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n75%        0.000000      0.000000       0.0       0.0       0.0       0.0   \nmax      187.000000    119.000000       0.0       0.0       0.0       0.0   \n\n       pixel783  \ncount   28000.0  \nmean        0.0  \nstd         0.0  \nmin         0.0  \n25%         0.0  \n50%         0.0  \n75%         0.0  \nmax         0.0  \n\n[8 rows x 784 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>...</td>\n      <td>28000.000000</td>\n      <td>28000.000000</td>\n      <td>28000.000000</td>\n      <td>28000.000000</td>\n      <td>28000.000000</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n      <td>28000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.164607</td>\n      <td>0.073214</td>\n      <td>0.028036</td>\n      <td>0.011250</td>\n      <td>0.006536</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5.473293</td>\n      <td>3.616811</td>\n      <td>1.813602</td>\n      <td>1.205211</td>\n      <td>0.807475</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>253.000000</td>\n      <td>254.000000</td>\n      <td>193.000000</td>\n      <td>187.000000</td>\n      <td>119.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 784 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ad75791b-a14c-464b-986d-bd548a0692e4",
        "_uuid": "0a314490edb9febc276eb45ddd47fe3461bd9d1d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#制作训练集，验证集和测试集\n#首先将数据按行随机打乱，然后进行切分，效果和train_test_split函数一样\n#注意要先进行打乱，再将X，Y分开，保证数据和标签一一对应\ndf_train = shuffle(df_train,random_state = 42)                             \n#用values可以讲数据框转换成不含有列名只含有内容的多维数组\ntrainXYorig = df_train.values\n#获取数据的行数\nm = trainXYorig.shape[0]\n#确定切分点，这里取行数的80%\npartition = int(m * 0.8)\n#将除开第一列标签的部分选取为列名，并且reshape成为四维数组，第一个维度是-1，代表的是样本数可以是任意张图片\ntrainXorig = trainXYorig[:, 1:].reshape(-1, 28, 28, 1)   #注意reshape是函数，因此接的是小括号\n#归一化\ntrainX = trainXorig / 255   \n#制作X的训练集和验证集，注意要先定义devX，否则trainX名字会更新，导致devX无法正常获取数据\ndevX = trainX[partition: , :, :, :]\ntrainX = trainX[0: partition, :, :, :]\n\n#取大矩阵的第一列为原始标签Y\ntrainYorig = trainXYorig[:, 0]\n#注意！！！将Y的标签从数字类别转化成独热向量，方便后面计算交叉熵，取10阶单位矩阵的第标签行作为新标签矩阵中对应的一行\ntrainY = np.eye(10)[trainYorig, :] \n#制作Y的训练集和验证集，同样的切分\ndevY = trainY[partition: , :]\ntrainY = trainY[0: partition, :]\n\n#测试集也要进行reshape\ntestXorig = df_test.values.reshape(-1, 28, 28, 1)\n#归一化\ntestX = testXorig / 255\n\n#输出各个数据集合的维数，查验是否出错\nprint(\"训练集X的形状是{} \".format(trainX.shape))\nprint(\"训练集Y的形状是{} \".format(trainY.shape))\nprint(\"验证集X的形状是{} \".format(devX.shape))\nprint(\"验证集Y的形状是{} \".format(devY.shape))\nprint(\"测试集X的形状是{} \".format(testX.shape))",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "训练集X的形状是(33600, 28, 28, 1) \n训练集Y的形状是(33600, 10) \n验证集X的形状是(8400, 28, 28, 1) \n验证集Y的形状是(8400, 10) \n测试集X的形状是(28000, 28, 28, 1) \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "5fd17880-b930-4905-b138-367f8a59ce94",
        "_uuid": "b83cae865cf0cd34370aadb8220c2ceceb7b50ef",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#画出一张图片，先选我们要花的第index张图片\nindex = 102\n#调用imshow的API，画出第index个样本的所有行，所有列，和第一个channel，cmap参数定义的是图片颜色，3channel图片无法定义cmap， interpolation可以定义缺失值插值方法（此处未用到）\nplt.imshow(trainX[index, :, :, 0], cmap ='gray')\n#给图片一个标题\nplt.title(\"No.{} picture,the label is {}\".format(index,trainYorig[index])) #标题中如果有中文无法正常显示？\nplt.show()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<matplotlib.figure.Figure at 0x7f7a3f90e710>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+W2zA1rv8/8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "5ac32118-2084-42c0-8b7a-79322b6bde3b",
        "_uuid": "67fb4d0d553723eb5391178b669cc43880b9cd60",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#设置一个随机小批量梯度下降用的生成mini_batch的函数\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    #先获得输入数据的总行数\n    m = X.shape[0]                  \n    #定义一个空的mini-batch的list，用来放所有的mini_batch\n    mini_batches = []\n    #设置随机数种子\n    np.random.seed(seed)\n    \n    #permutation和shuffle类似，都是随机打乱，区别是permutation是返回一个被打乱的序列，原序列不变，shuffle直接改变原序列\n    #如果permutation的变量用的是一个integer，那么会直接打乱np.arange(m),如下所示，会得到一个乱序的值为0~m-1的list\n    permutation = list(np.random.permutation(m))\n    #得到一个打乱的X和Y，维数索引是前面的被打乱的m\n    shuffled_X = X[permutation,:,:,:]\n    shuffled_Y = Y[permutation,:]\n    \n    #计算mini_batch的个数，mini_batch_size是函数里面给出的，int函数取整是取整数部分舍弃小数部分\n    num_complete_minibatches = int(m / mini_batch_size) \n    #对整个被打乱的X切片处理，并循环操作，得到一个很多mini_batch\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[k * mini_batch_size: (k + 1) * mini_batch_size, :, :, :]\n        mini_batch_Y = shuffled_Y[k * mini_batch_size: (k + 1) * mini_batch_size, :]\n        #每一个小batch都由打乱的X，Y拼成\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        #组合所有的小batch\n        mini_batches.append(mini_batch)\n    \n    #如果总的样本数不能被mini_batch的个数整除，将剩余的样本也补充进来\n    if (m % mini_batch_size != 0):\n        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: m, :, :, :]\n        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: m, :]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    #最后返回的是mini_batches的组合\n    return mini_batches",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4bfb46c6-f752-48d9-b7dd-24d256bf2ffe",
        "_uuid": "6018c9da6a89890b27aa5be8cb0306e126daff54"
      },
      "cell_type": "markdown",
      "source": "CNN"
    },
    {
      "metadata": {
        "_cell_guid": "5b4ee670-c605-4b15-9ef4-843083fb4fc8",
        "_uuid": "aab8009bf9c1d797009b2f365109e851d3ac124f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 定义X，Y两个占位符\nX = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name = \"X\")\nY = tf.placeholder(dtype=tf.float32, shape=[None, 10], name = \"Y\")\n#定义一个布尔型变量的占位符，用来确定是不是在计算图需要训练的部分。\n#一张计算图里面根据你要fetch的值的不同，有些部分是不参与训练的。batch_norm层里面需要用到这个参数。对输出的均值和方差有影响。\nis_training = tf.placeholder(tf.bool)    \n#打印出来，确认X，Y的类型和维度是否正确\nprint(\"X = \" + str(X))\nprint(\"Y = \" + str(Y))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "X = Tensor(\"X:0\", shape=(?, 28, 28, 1), dtype=float32)\nY = Tensor(\"Y:0\", shape=(?, 10), dtype=float32)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "05d5444b-23eb-4b6f-a940-beb031f0f0e4",
        "_uuid": "9745fb8913dd0de03626225702cffadc9c9bcb56",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# 定义W1，W2，W3三个参数，也就是卷积核；get_variable 和 variable 类似，有则调用，无则新建\n# leNet-5 只有两层卷积层，这里定义了三层，扩大了网络规模\n# 初始化方法采用的是泽维尔初始化，这种方法的好处是可以使得每层输出的方差大致相等，使得信息能够在网络中更好的流动，具体方法是在某个均匀分布中实现初始化\n#卷积核的前两个维度是单层卷积核的维度，也就是它的长和宽，第三个维度是上一层的channel的个数，第三个维度是卷积核总共的层数\nW1 = tf.get_variable(\"W1\", shape=[3, 3, 1, 4], initializer=tf.contrib.layers.xavier_initializer())  #每个卷积核都要定义名字，形状和初始化方法\nW2 = tf.get_variable(\"W2\", shape=[3, 3, 4, 8], initializer=tf.contrib.layers.xavier_initializer())\nW3 = tf.get_variable(\"W3\", shape=[3, 3, 8, 8], initializer=tf.contrib.layers.xavier_initializer()) ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "dde71f0a-5eb1-47f9-915a-42c2699f7961",
        "_uuid": "9f3a2e3c2ce5c5d199c11d0e62ea4c25de186c88",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 定义第一层网络结构，架构是:卷积运算 CONV2D(Z1) -> 批标准化 BatchNorm(N1) -> 激活函数 RELU(A1) -> 最大池化层 MAXPOOL(P1) -> \nZ1 = tf.nn.conv2d(input=X, filter=W1, strides=[1, 1, 1, 1], padding='SAME')    #conv2d 在tf.nn模块，需要定义输入，卷积核，步长和padding。padding分为same padding和valid padding 两种\nN1 = tf.layers.batch_normalization(Z1, training=is_training)      #批标准化在tf.layers模块！！！批标准化可以加速网络的计算\nA1 = tf.nn.relu(N1)   #对上一层的结果取激活函数为relu：max{x，0}\n#至此，卷积部分定义完毕，接下来是池化\nP1 = tf.nn.max_pool(value=A1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")  #池化层也需要padding；池化层的尺寸和步长设置貌似和卷积核不一样？\n\n# 定义第二层网络结构，架构是:卷积运算 CONV2D(Z2) -> 批标准化 BatchNorm(N2) -> 激活函数 RELU(A2) -> 最大池化层 MAXPOOL(P1) ->  \nZ2 = tf.nn.conv2d(input=P1, filter=W2, strides=[1, 1, 1, 1], padding='SAME')\nN2 = tf.layers.batch_normalization(Z2, training=is_training)\nA2 = tf.nn.relu(N2)\nP2 = tf.nn.max_pool(value=A2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n# 定义第三层网络结构，架构是:卷积运算 CONV2D(Z3) -> 批标准化 BatchNorm(N3) -> 激活函数 RELU(A3) -> 最大池化层 MAXPOOL(P1) -> \nZ3 = tf.nn.conv2d(input=P2, filter=W3, strides=[1, 1, 1, 1], padding='SAME')\nN3 = tf.layers.batch_normalization(Z3, training=is_training)\nA3 = tf.nn.relu(N3)\nP3 = tf.nn.max_pool(value=A3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n# 定义第四层网络结构，架构是:扁平化层 FLATTEN(F3) -> 全连接层 FULLYCONNECTED(Z4) -> 批标准化 BatchNorm(N4) -> 激活函数 RELU(A4)\nF3 = tf.contrib.layers.flatten(P3)    #contrib模块包含的是有试验性质的新方法\nZ4 = tf.contrib.layers.fully_connected(F3, num_outputs=64, activation_fn=None)    #总共要接两层全连接层，这是第一层，包含64个神经元，没有激活函数\nN4 = tf.layers.batch_normalization(Z4, training=is_training)    #批标准化\nA4 = tf.nn.relu(N4)\n\n# 定义第五层网络结构，仅含有一个全连接层做softmax层，64 to 10\nZ5 = tf.contrib.layers.fully_connected(A4, num_outputs=10, activation_fn=None)\n\n# 代价函数，reducemean就是对某一个维度求平均，可以搭配axis使用，没有axis的话，就是对所有维度求平均。\n# 注意！！！以后不用with logits了，要用with logits v2\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=Y))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a24f3b75-4ae2-44f7-b9a4-9595df93660e",
        "_uuid": "5a9096fbb55602505b9f60242f3b15c9ca29e9f6",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 定义超参数\nlearning_rate = 0.002\nnum_epochs = 50\nmini_batch_size = 64\n# 初始化costs，为一个空列表\ncosts = []",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "89f527f7-b971-4562-968b-539a383ddf35",
        "_uuid": "98b6005d5c044d5807a99740faa423339109aec0",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 定义优化器\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n# 变量初始化\ninit = tf.global_variables_initializer()                                      ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "95d2eaef-6658-401e-b5f9-7ca6fc11320c",
        "_uuid": "d8143ae92ff9720743fce0b58dc9167dc7264cd5",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 开启新会话，并且初始化\nsess = tf.Session()\nsess.run(init)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "00796074-8ac5-4909-b338-4b682b5a9baa",
        "_uuid": "bfc9305e1f1cadc3a6fad94f502575308a3d1ba2",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 通过collection存储\nextra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "65a8e8f6-0ea7-4182-b262-a09cc2df90b8",
        "_uuid": "93ee71e9a512fb9947807bf8cf78eb262e0b862d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 第一层循环，从大周期epoch开始\nfor epoch in range(num_epochs):\n    # random_mini_batches函数，返回的是由很多mini_batch组成的mini_batches的列表\n    minibatches = random_mini_batches(trainX, trainY, mini_batch_size=mini_batch_size, seed=epoch + int(time.time()))\n    # 初始化epochcost\n    epoch_cost = 0.\n    \n    # 第二层循环，在minibatches列表内部循环\n    for minibatch in minibatches:\n        # ？？？\n        (minibatchX, minibatchY) = minibatch\n        # 不需要返回的值，可以赋值给空格；sess.run的参数，第一项是要fetch的值，第二项是feed_dict；计算上面定义的cost\n        _, mini_batch_cost, __ = sess.run([optimizer, cost, extra_update_ops], feed_dict={X: minibatchX, Y: minibatchY, is_training:True})\n        # 每一个epoch的cost等于所有mini_batch的cost相加\n        epoch_cost += mini_batch_cost\n\n    # 对epoch_cost 求平均\n    epoch_cost /= len(minibatches)\n    # 在costs列表 加上上一个epoch的cost\n    costs.append(epoch_cost)\n    # 如果 epoch是偶数（只输出一半的值）\n    if epoch % 2 == 0:\n        # 格式化输出，%d是数字，%f是浮点数\n        print(\"No. %d epoch, cost = %f\" % (epoch, epoch_cost))\n\n# 用plt画随着epoch变化costs的曲线\nplt.plot(costs)\nplt.xlabel(\"number of epochs\")\nplt.ylabel(\"cost\")\nplt.title(\"cost\")",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "No. 0 epoch, cost = 0.304607\nNo. 2 epoch, cost = 0.074841\nNo. 4 epoch, cost = 0.051612\nNo. 6 epoch, cost = 0.040223\nNo. 8 epoch, cost = 0.033056\nNo. 10 epoch, cost = 0.029123\nNo. 12 epoch, cost = 0.024198\nNo. 14 epoch, cost = 0.020645\nNo. 16 epoch, cost = 0.018072\nNo. 18 epoch, cost = 0.016474\nNo. 20 epoch, cost = 0.014202\nNo. 22 epoch, cost = 0.013142\nNo. 24 epoch, cost = 0.012574\nNo. 26 epoch, cost = 0.011786\nNo. 28 epoch, cost = 0.010974\nNo. 30 epoch, cost = 0.010748\nNo. 32 epoch, cost = 0.008687\nNo. 34 epoch, cost = 0.008640\nNo. 36 epoch, cost = 0.009932\nNo. 38 epoch, cost = 0.008654\nNo. 40 epoch, cost = 0.006929\nNo. 42 epoch, cost = 0.008309\nNo. 44 epoch, cost = 0.005757\nNo. 46 epoch, cost = 0.006031\nNo. 48 epoch, cost = 0.008330\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "Text(0.5,1,'cost')"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<matplotlib.figure.Figure at 0x7f7a3e87afd0>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMblcPCzMxG9f8BHhH8Gzlt700AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ec54aa81-c82d-46e6-b9bf-286fe0e6b279",
        "_uuid": "3a10f27b56d7306b4e0d8553c878fd8a65fdc9bf"
      },
      "cell_type": "markdown",
      "source": "Evaluation"
    },
    {
      "metadata": {
        "_cell_guid": "a9094741-3135-42bc-ba7e-36ead5cf178f",
        "_uuid": "a86782f32601b788a5c90422b548efcdd051c598",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# predict_op返回的是向量沿轴线方向的最大值的索引\npredict_op = tf.argmax(Z5, 1)\n# tf.equal 返回的是一个全是bool值变量的数组，相同返回True，不同返回False\ncorrect_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n# 将布尔型变化成浮点型，True为1，False为0.然后求平均，可以得到平均正确率\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d6c84bdc-4c2c-4274-9816-e49f3e323700",
        "_uuid": "309fb3d98140e52d108b6fe982c3e06d3bdb8303",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# eval()也是启动计算的一种方式。基于Tensorflow的基本原理，首先需要定义图，然后计算图，其中计算图的函数常见的有run()函数，如sess.run()。同样eval()也是此类函数，是sess.run()的另外一种写法。\n# 计算训练集误差\n# ？？？is_training标记为False的时候不会执行dropout等操作。注意is_training是放在feed_dict里面的\ntrain_accuracy = accuracy.eval(session=sess, feed_dict={X: trainX, Y: trainY, is_training:False})    \n# 计算验证集误差\ndev_accuracy = accuracy.eval(session=sess, feed_dict={X: devX, Y: devY, is_training:False})\n# 输出\nprint(\"train_accuracy = \" + str(train_accuracy))\nprint(\"dev_accuracy = \" + str(dev_accuracy))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "train_accuracy = 0.9993155\ndev_accuracy = 0.9842857\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "96077bc0-2e64-467e-bac8-9cc94e591a1f",
        "_uuid": "754cd8bbe015c1831b1e08197dc0f430e2574f84",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 计算测试集预测值\ntestY_pred = predict_op.eval(session=sess, feed_dict={X: testX, is_training:False})\n# 保存成一个一列dataframe，列标签是Label\ntestYDf = pd.DataFrame(testY_pred.reshape(-1, 1), index=np.arange(1, 1 + len(testY_pred)), columns=[\"Label\"]) # index 要求从 1 开始\ntestYDf.to_csv(\"test_predict.csv\", index=True, index_label=\"ImageId\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d0a3c17423f872b6924087eb4efcf62ba036a41f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}